# WordEmbeddings
## Description
[Word Embeddings](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa) and [Contextual Word Vectors](https://stackoverflow.com/questions/62272056/what-are-the-differences-between-contextual-embedding-and-word-embedding) are Natural Language Processing tools that allow you to capture context of a word within a document, relation to other words, and semanatic and syntactic similarity. 
This pipeline constructs word vector models (word2vec) which convert words into their vector representations, allowing you to compare words using metrics like cosine similarity. A future implementation will contain code to setup a BERT model.

**IMPORTANT:** For more details, see the [example](https://github.com/patriChiril/miie_beta/tree/main/examples/wordEmbeddings) and the [setup instructions](https://github.com/patriChiril/miie_beta/blob/main/documentation/user_documentation/wordEmbeddings.md).

